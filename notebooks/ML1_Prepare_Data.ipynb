{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this notebook before the ML notebook\n",
    "* This notebook requires down_up_lat_tests_by_quarter_part[1-5].csv in the current directory\n",
    "* This notebook reads chunks of raw data and prepares a large feature_table \n",
    "* Runtime about 2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data = pd.DataFrame()\n",
    "number_of_chunks = 5\n",
    "for idx in range(1, number_of_chunks+1):\n",
    "    time_data = pd.concat([time_data, pd.read_csv(f\"down_up_lat_tests_by_quarter_part{idx}.csv\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['quadkey', 'geometry', 'd2019Q1', 'u2019Q1', 'l2019Q1', 't2019Q1',\n",
      "       'd2019Q2', 'u2019Q2', 'l2019Q2', 't2019Q2',\n",
      "       ...\n",
      "       'tile_area', 'tile_frac', 'das_frac', 'DAPOP', 'POP_DENSITY', 'PCUID',\n",
      "       'PCNAME', 'PCTYPE', 'PCPUID', 'PCCLASS'],\n",
      "      dtype='object', length=103)\n",
      "(581765, 103)\n",
      "(581765, 85)\n"
     ]
    }
   ],
   "source": [
    "print(time_data.columns)\n",
    "print(time_data.shape)\n",
    "cols_to_drop = ['geometry','DAUID','PRUID','CDUID','CCSUID','CCSNAME','CSDUID','ERUID','SACCODE','CMAUID','CMAPUID','CMANAME','CMATYPE','CTUID','CTNAME','ADAUID','PCUID','PCPUID']\n",
    "time_data = time_data.drop(columns=cols_to_drop).reset_index(drop=True)\n",
    "print(time_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_cols = [col for col in time_data if col.startswith('d20')]\n",
    "up_cols = [col for col in time_data if col.startswith('u20')]\n",
    "lat_cols = [col for col in time_data if col.startswith('l20')]\n",
    "tests_cols = [col for col in time_data if col.startswith('t20')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds n previous quarters given the curent year(y) and quarter(q)\n",
    "def training_quarters(y, q, n):\n",
    "    quarters = []\n",
    "    i=0\n",
    "    while i<5:\n",
    "        if q<=i:\n",
    "            i = 0\n",
    "            y = y-1\n",
    "            q=4\n",
    "        else:\n",
    "            quarters.append(str(y) + \"Q\" + str(q-i))\n",
    "            i=i+1\n",
    "            if len(quarters) == n:\n",
    "                return quarters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "(581765, 53)\n",
      "(1163530, 53)\n",
      "(1745295, 53)\n",
      "(2327060, 53)\n",
      "(2908825, 53)\n",
      "(3490590, 53)\n",
      "(4072355, 53)\n",
      "(4654120, 53)\n",
      "(5235885, 53)\n"
     ]
    }
   ],
   "source": [
    "# Select a quarter as target and add corresponding features using def training_quarters()\n",
    "feature_table = pd.DataFrame()\n",
    "print(feature_table.shape)\n",
    "\n",
    "n_train_quarter = 8\n",
    "n_quarter = n_train_quarter+1\n",
    "\n",
    "for year in range(2021, 2023):\n",
    "    new_table = time_data.drop(columns=down_cols+up_cols+lat_cols+tests_cols)\n",
    "    for quarter in range(1, 5):\n",
    "        quarters = training_quarters(year, quarter, n_quarter)\n",
    "        for i in range(n_quarter):\n",
    "            new_table[\"d_quarter\"+str(i)] = time_data[\"d\"+quarters[i]]\n",
    "            new_table[\"u_quarter\"+str(i)] = time_data[\"u\"+quarters[i]]\n",
    "            new_table[\"l_quarter\"+str(i)] = time_data[\"l\"+quarters[i]]\n",
    "            new_table[\"t_quarter\"+str(i)] = time_data[\"t\"+quarters[i]]\n",
    "\n",
    "        feature_table = pd.concat([feature_table, new_table], ignore_index=True)\n",
    "        print(feature_table.shape)\n",
    "\n",
    "year=2023\n",
    "quarter=1\n",
    "new_table = time_data.drop(columns=down_cols+up_cols+lat_cols+tests_cols)\n",
    "quarters = training_quarters(year, quarter, n_quarter)\n",
    "for i in range(n_quarter):\n",
    "    new_table[\"d_quarter\"+str(i)] = time_data[\"d\"+quarters[i]]\n",
    "    new_table[\"u_quarter\"+str(i)] = time_data[\"u\"+quarters[i]]\n",
    "    new_table[\"l_quarter\"+str(i)] = time_data[\"l\"+quarters[i]]\n",
    "    new_table[\"t_quarter\"+str(i)] = time_data[\"t\"+quarters[i]]\n",
    "\n",
    "feature_table = pd.concat([feature_table, new_table], ignore_index=True)\n",
    "print(feature_table.shape) # Watch the feature table become larger with each new quarter as target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 90 seconds to save the csv file. over 1 GB file.\n",
    "feature_table.to_csv(\"feature_table_by_quarter.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ookla-statcan-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
