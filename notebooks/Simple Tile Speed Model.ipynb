{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4923ec2c",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Starting point for a supervised learning model for Ookla speed tiles. The data comes from a combination of \n",
    "Ookla Open Data speed tests and Statistics Canada information, including 2016 census population data and census boundaries (shapefiles). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e11b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59298bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0120861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.loading import statcan, ookla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a651b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import geopandas as gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7747ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, pipeline, compose\n",
    "from sklearn import linear_model, model_selection, svm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28af861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14697af4",
   "metadata": {},
   "source": [
    "## Load \n",
    "Load some of the available data. The census population data and StatCan boundaries are automatically loaded from \n",
    "the StatCan website. The overlays and tile geometries/speeds need to pre-computed and saved to the overlays directory and data directories. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dee2f19",
   "metadata": {},
   "source": [
    "### Load All Unique Tile Gemoetries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f33da9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ookla_tiles = ookla.canada_tiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99eb5de",
   "metadata": {},
   "source": [
    "### Load Census Population Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6832deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_pops = statcan.dissemination_areas_populations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f62db26",
   "metadata": {},
   "source": [
    "### Labelling Tiles\n",
    "Generate labels from geometric overlay of the Ookla tiles and Statistics Canada Dissemination Areas (DA). \n",
    "Label each tile with the information from the StatCan areas based on which DA the tile overlaps the most with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2a7bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = gp.read_file(src.config.OVERLAYS_DIR / 'tile_das_overlay') #this can take a few minutes to load.\n",
    "tile_da_label = o.dropna(subset=['DAUID','quadkey']).sort_values(by=['quadkey','tile_frac'],ascending=False).drop_duplicates(subset='quadkey', keep='first')\n",
    "tile_da_label['quadkey'] = tile_da_label['quadkey'].astype(int)\n",
    "tile_da_label['DAUID'] = tile_da_label['DAUID'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0112f24",
   "metadata": {},
   "source": [
    "### Speed Test Data\n",
    "Load in the previous 4 quarters of data. Since we're currently in Q3 of 2022, the most recent quarter is Q2 \n",
    "so we can slice the files listed to grab those. Subsequently, we'll calculate weighted averages for individual tiles and use those as representative speeds for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246ca578",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_4_quarters = ookla.speed_data(ookla.available_files().loc[('fixed',2021,3):('fixed',2022,2)].path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8149cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "down = last_4_quarters.groupby('quadkey').apply(lambda s:np.average(s.avg_d_kbps, weights=s.tests)).rename('avg_d_kbps')\n",
    "up = last_4_quarters.groupby('quadkey').apply(lambda s:np.average(s.avg_u_kbps, weights=s.tests)).rename('avg_u_kbps')\n",
    "tests = last_4_quarters.groupby('quadkey')['tests'].sum()\n",
    "devices = last_4_quarters.groupby('quadkey')['devices'].sum()\n",
    "last4_agg = pd.concat([down, up, tests, devices],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd02857a",
   "metadata": {},
   "source": [
    "### Merge All The Data\n",
    "It's a bit messy, but we're merging several tables and removing a few of the redundant or non-useful \n",
    "columns as we go through. At the end the `features_table` variable will have all of the \n",
    "tiles within census areas labelled by what type of Census Subdivision, Dissemination Area, Population Centre, etc. they are in, as well as population information for the DA (smallest area with populations available) and the speed test averages over the last 4 quarters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge dissemination area (DA) populations with ookla tiles (already combined with other statcan data)\n",
    "features_table = tile_da_label.merge(da_pops, on='DAUID', how='left')\n",
    "features_table['DAPOP'] = features_table['DAPOP'].fillna(0).astype(int)\n",
    "del features_table['GEO_NAME']\n",
    "features_table = pd.DataFrame(features_table)\n",
    "del features_table['geometry']\n",
    "features_table['POP_DENSITY'] = features_table['DAPOP']/features_table['das_area']*1000**2 #people per square kilometer\n",
    "\n",
    "# take all ookla tiles, merge the speeds data and tile labels and populations\n",
    "features_table = ookla_tiles.merge(last4_agg, on='quadkey').merge(features_table, on='quadkey')\n",
    "\n",
    "# compute spatial joins to identify if area is a population centre\n",
    "pop_info = statcan.boundary('population_centres').to_crs('epsg:4326')\n",
    "pop_info = pop_info[['PCUID', 'PCNAME', 'PCTYPE', 'PCPUID', 'PCCLASS', 'geometry']] ##removes some redundant cols from DAs\n",
    "features_table = features_table.sjoin(pop_info, how='left')\n",
    "del features_table['index_right']\n",
    "features_table = features_table.sort_values(by=['PCUID','quadkey']).drop_duplicates(subset=['quadkey']) #keep tiles where overlap was true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad6d808",
   "metadata": {},
   "source": [
    "### Categorize All the Columns\n",
    "All the columns from our joins above can be roughly split into categories based on the type of \n",
    "data and how you might use them in a simple supervised learning problem. These are broken down as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9a4ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkey = 'quadkey'\n",
    "geometry = 'geometry'\n",
    "id_and_names = ['DAUID', 'CDUID', 'CDNAME', 'CCSUID', 'CSDNAME', 'CMAUID', 'CMAPUID', 'CMANAME', \n",
    "'CCSNAME', 'CSDUID', 'ERUID', 'ERNAME', 'CTUID', 'CTNAME', 'ADAUID', \n",
    "'PCUID', 'PCNAME', 'PCPUID', 'SACCODE',] ##SACCODE is half a category half ID values\n",
    "\n",
    "categorical_labels = [\n",
    "    #'PRUID', #PRUID is redundant with PRNAME\n",
    "    'PRNAME', 'CDTYPE', \n",
    "    'CSDTYPE',  \n",
    "    'SACTYPE', \n",
    "    'CMATYPE', 'PCTYPE', 'PCCLASS',\n",
    "]\n",
    "numerical_vars = [\n",
    "    'tests', 'devices',\n",
    "    'das_area', 'tile_area', 'tile_frac',  'das_frac', \n",
    "    'DAPOP','POP_DENSITY'\n",
    "]\n",
    "target_vars = ['avg_d_kbps', 'avg_u_kbps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dbe082",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_subset = [pkey] + categorical_labels + numerical_vars + target_vars\n",
    "features_table.loc[:,col_subset].set_index('quadkey')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8be3148",
   "metadata": {},
   "source": [
    "## Train A Simple ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090f8841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard train/test where down and/or up speeds are the target/predicted continuous variable.\n",
    "X_train, X_test, \\\n",
    "down_train, down_test, \\\n",
    "up_train, up_test = model_selection.train_test_split(\n",
    "    features_table, features_table['avg_d_kbps'], features_table['avg_u_kbps']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddda64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the numerical Data and OneHot encode the categorical vars.\n",
    "colTransformer = compose.ColumnTransformer(\n",
    "    [(f\"{cat}\",preprocessing.OneHotEncoder(),[cat]) for cat in categorical_labels] \\\n",
    "    + [(f\"{num}\", preprocessing.StandardScaler(), [num]) for num in numerical_vars] \n",
    "    #+ [(f\"{y}_stdscaler\", preprocessing.StandardScaler(), [y]) for y in target_vars]\n",
    ")\n",
    "\n",
    "#Setup a regressor for predicting down/up speeds.\n",
    "ridge = linear_model.RidgeCV()\n",
    "regressor = compose.TransformedTargetRegressor(\n",
    "    regressor=ridge,\n",
    "    transformer=preprocessing.PowerTransformer(method='box-cox')\n",
    ")\n",
    "\n",
    "# Combine above in a reuseable pipeline object\n",
    "pipe = pipeline.Pipeline([\n",
    "    ('preprocess',colTransformer),\n",
    "    ('regressor', regressor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa59beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "pipe.fit(X_train, down_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa38026b",
   "metadata": {},
   "source": [
    "### Look at Some Analytics\n",
    "The performance isn't very good, specifically if we consider the context of \n",
    "determining if individuals can access internet at the Federal 50/10 Mbps commitment level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dfb7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how did it do on the training set\n",
    "# speeds are in kbps\n",
    "{\"Mean Absolute Error\":metrics.mean_absolute_error(pipe.predict(X_train), down_train),\n",
    "\"Median Absolute Error\":metrics.median_absolute_error(pipe.predict(X_train), down_train),\n",
    "\"Mean Absolute Percentage Error\":metrics.mean_absolute_percentage_error(pipe.predict(X_train), down_train)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b22cb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(14,6))\n",
    "axs[0].scatter(down_train, pipe.predict(X_train), alpha=0.05);\n",
    "axs[0].set(xlabel=\"Measured Down Speed (kbps)\", ylabel=\"Predicted Down Speed (kbps)\");\n",
    "\n",
    "bins = np.linspace(-60000,800000,100)\n",
    "axs[1].hist(down_train,alpha=0.5, bins=bins,label='Predited')\n",
    "axs[1].hist(pipe.predict(X_train),alpha=0.5, bins=bins,label='ML Fit');\n",
    "axs[1].legend()\n",
    "axs[1].set(xlabel='Download Speed (kbps)', ylabel='Tile Count (N)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e7ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the important coefficients.\n",
    "coefs = pd.DataFrame(pipe[-1].regressor_.coef_,columns=['Coefficients'],index=pipe[:-1].get_feature_names_out())\n",
    "coefs.sort_values(by='Coefficients').plot.barh(figsize=(8,20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('datascience')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "7baa5682b3ee41d95f3e6c53f6f101854543f295d881c00164f5d254f1692751"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
